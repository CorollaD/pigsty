---
#------------------------------------------------------------------------------
# Pigsty configuration file
#------------------------------------------------------------------------------
#
# This file using yaml format
#
# This file is used as default settings for all cluster. it will override role's
# default variable, and will be override by host inventory variables
#
#------------------------------------------------------------------------------


#------------------------------------------------------------------------------
# CONNECTION PARAMETERS
#------------------------------------------------------------------------------
# this section defines connection parameters

# ansible_user: vagrant             # admin user with ssh access and sudo privilege

#proxy_env: {}
proxy_env:                          # global proxy env when downloading packages
  http_proxy: "http://employee2:XgKCXtf5WH@proxy.p1staff.com:1337"
  https_proxy: "http://employee2:XgKCXtf5WH@proxy.p1staff.com:1337"
  no_proxy: "localhost,127.0.0.1,10.0.0.0/8,192.168.0.0/16,*.pigsty,*.aliyun.com"


#------------------------------------------------------------------------------
# REPO PROVISION
#------------------------------------------------------------------------------
# this section defines how to build a local repo

repo_enabled: true                            # build local yum repo on meta nodes?
repo_name: pigsty                             # local repo name
repo_address: yum.pigsty                      # repo external address (ip:port or url)
repo_port: 80                                 # listen address, must same as repo_address
repo_home: /www                               # default repo dir location
repo_rebuild: false                           # force re-download packages
repo_remove: true                             # remove existing repos
# repo_upstreams: []                          # use role default upstream
# repo_packages: []                           # use role default packages
# repo_url_packages: []                       # use role default web urls


#------------------------------------------------------------------------------
# NODE PROVISION
#------------------------------------------------------------------------------
# this section defines how to provision nodes

# - node dns - #
node_dns_hosts:                               # static dns records in /etc/hosts
  - 10.10.10.10 yum.pigsty
node_dns_server: add                          # add (default) | none (skip) | overwrite (remove old settings)
node_dns_servers:                             # dynamic nameserver in /etc/resolv.conf
  - 10.10.10.10
node_dns_options:                             # dns resolv options
  - options single-request-reopen timeout:1 rotate
  - domain service.consul

# - node repo - #
node_repo_method: local                       # none|local|public (use local repo for production env)
node_repo_remove: true                        # whether remove existing repo
node_local_repo_url:                          # local repo url (if method=local)
  - http://yum.pigsty/pigsty.repo

# - node packages - #
node_extra_packages: []                       # extra packages for all nodes
# node_packages: []                           # common packages for all nodes (use role default)
# node_meta_packages: []                      # packages for meta nodes only (use role default)

# - node features - #
node_disable_numa: false                      # disable numa, important for production database, reboot required
node_disable_swap: true                       # disable swap, important for production database
node_disable_firewall: true                   # disable firewall (required if using kubernetes)
node_disable_selinux: true                    # disable selinux  (required if using kubernetes)
node_static_network: true                     # keep dns resolver settings after reboot
node_disk_prefetch: false                     # setup disk prefetch on HDD to increase performance

# - node kernel modules - #
node_kernel_modules: [softdog, br_netfilter, ip_vs, ip_vs_rr, ip_vs_rr, ip_vs_wrr, ip_vs_sh, nf_conntrack_ipv4]

# - node tuned - #
node_tuned: true                              # install and activate tuned profile: postgres
node_sysctl_params:                           # set additional sysctl parameters, k:v format
  net.bridge.bridge-nf-call-iptables: 1       # for kubernetes

# - node user - #
node_admin_setup: true                        # setup an default admin user ?
node_admin_uid: 88                            # uid and gid for admin user
node_admin_username: admin                    # default admin user
node_admin_ssh_exchange: true                 # exchange ssh key among cluster ?
node_admin_pks: []                            # public key list that will be installed

# - node ntp - #
node_ntp_service: ntp                         # ntp or chrony
node_ntp_config: true                         # overwrite existing ntp config?
node_timezone: Asia/Shanghai                  # default node timezone
node_ntp_servers:                             # default NTP servers
  - pool cn.pool.ntp.org iburst
  - pool pool.ntp.org iburst
  - pool time.pool.aliyun.com iburst
  - server 10.10.10.10 iburst


#------------------------------------------------------------------------------
# META PROVISION
#------------------------------------------------------------------------------
# - ca - #
ca_method: create                             # create|copy|recreate
ca_subject: "/CN=root-ca"                     # self-signed CA subject
ca_homedir: /ca                               # ca cert directory
ca_cert: ca.crt                               # ca public key/cert
ca_key: ca.key                                # ca private key

# - nginx - #
nginx_upstream:
  - {name: consul,        host: c.pigsty, url: "http://localhost:8500/"}
  - {name: grafana,       host: g.pigsty, url: "http://localhost:3000/"}
  - {name: prometheus,    host: p.pigsty, url: "http://localhost:9090/"}
  - {name: alertmanager,  host: a.pigsty, url: "http://localhost:9093/"}

# - nameserver - #
dns_records:                                  # dynamic dns record resolved by dnsmasq
  - 10.10.10.2  pg-meta                       # sandbox vip for pg-meta
  - 10.10.10.3  pg-test                       # sandbox vip for pg-test
  - 10.10.10.10 meta-1                        # sandbox node meta-1 (node-0)
  - 10.10.10.11 node-1                        # sandbox node node-1
  - 10.10.10.12 node-2                        # sandbox node node-2
  - 10.10.10.13 node-3                        # sandbox node node-3
  - 10.10.10.10 pigsty
  - 10.10.10.10 y.pigsty yum.pigsty
  - 10.10.10.10 c.pigsty consul.pigsty
  - 10.10.10.10 g.pigsty grafana.pigsty
  - 10.10.10.10 p.pigsty prometheus.pigsty
  - 10.10.10.10 a.pigsty alertmanager.pigsty
  - 10.10.10.10 n.pigsty ntp.pigsty

# - prometheus - #
prometheus_scrape_interval: 2s                # global scrape & evaluation interval (2s for dev, 15s for prod)
prometheus_scrape_timeout: 1s                 # global scrape timeout (1s for dev, 8s for prod)
prometheus_metrics_path: /metrics             # default metrics path (only affect job 'pg')
prometheus_data_dir: /export/prometheus/data  # prometheus data dir
prometheus_retention: 30d                     # how long to keep

# - grafana - #
grafana_url: http://localhost:3000             # grafana url
grafana_admin_password: admin                  # default grafana admin user password
grafana_plugin: install                        # none|install|reinstall
grafana_cache: /www/pigsty/grafana/plugins.tar.gz # path to grafana plugins tarball
grafana_provision_mode: db                     # none|db|api
# grafana_plugins: []                          # grafana plugins list (use role default)
# grafana_git_plugins: []                      # grafana plugins from git (use role default)
# grafana_dashboards: []                       # default dashboards (use role default)


#------------------------------------------------------------------------------
# DCS PROVISION
#------------------------------------------------------------------------------
dcs_type: consul                              # consul | etcd | both
dcs_name: pigsty                              # consul dc name | etcd initial cluster token
dcs_servers:                                  # dcs server dict in name:ip format
  meta-1: 10.10.10.10                         # you could use existing dcs cluster
  # meta-2: 10.10.10.11                       # host which have their IP listed here will be init as server
  # meta-3: 10.10.10.12                       # 3 or 5 dcs nodes are recommend for production environment

dcs_exists_action: skip                       # abort|skip|clean if dcs server already exists
consul_data_dir: /var/lib/consul              # consul data dir (/var/lib/consul by default)
etcd_data_dir: /var/lib/etcd                  # etcd data dir (/var/lib/consul by default)


#------------------------------------------------------------------------------
# POSTGRES PROVISION
#------------------------------------------------------------------------------
# - dbsu - #
pg_dbsu: postgres               # os user for database, postgres by default (change it is not recommended!)
pg_dbsu_uid: 26                 # os dbsu uid and gid, 26 for default postgres users and groups
pg_dbsu_sudo: limit             # none|limit|all|nopass (Privilege for dbsu, limit is recommended)
pg_dbsu_home: /var/lib/pgsql    # postgresql binary
pg_dbsu_ssh_exchange: true      # exchange ssh key among same cluster

# - dbsu - #
pg_version: 12                  # default postgresql version
pgdg_repo: false                # use official pgdg yum repo (disable if you have local mirror)
pg_bin_dir: /usr/pgsql/bin      # postgres binary directory

pg_packages:
  - postgresql${pg_version}* postgis30_${pg_version}* timescaledb_${pg_version} citus_${pg_version} pglogical_${pg_version}   # postgres ${pg_version} basic
  - pg_qualstats${pg_version} pg_cron_${pg_version} pg_top${pg_version} pg_repack${pg_version} pg_squeeze${pg_version} pg_stat_kcache${pg_version} wal2json${pg_version} pgpool-II-${pg_version} pgpool-II-${pg_version}-extensions
  - pgbouncer patroni pg_exporter pg_top pgbadger # postgres common utils

pg_extensions: []
# - ddlx_${pg_version} bgw_replstatus${pg_version} count_distinct${pg_version} extra_window_functions_${pg_version} geoip${pg_version} hll_${pg_version} hypopg_${pg_version} ip4r${pg_version} jsquery_${pg_version} multicorn${pg_version} osm_fdw${pg_version} mysql_fdw_${pg_version} ogr_fdw${pg_version} mongo_fdw${pg_version} hdfs_fdw_${pg_version} cstore_fdw_${pg_version} wal2mongo${pg_version} orafce${pg_version} osm2pgrouting_${pg_version} pagila${pg_version} pam-pgsql${pg_version} passwordcheck_cracklib${pg_version} periods_${pg_version} pg_auto_failover_${pg_version} pg_bulkload${pg_version} pg_catcheck${pg_version} pg_comparator${pg_version} pg_filedump${pg_version} pg_fkpart${pg_version} pg_jobmon${pg_version} pg_partman${pg_version} pg_pathman${pg_version} pg_track_settings${pg_version} pg_wait_sampling_${pg_version} pgagent_${pg_version} pgaudit14_${pg_version} pgauditlogtofile-${pg_version} pgbconsole${pg_version} pgcryptokey${pg_version} pgexportdoc${pg_version} pgfincore${pg_version} pgimportdoc${pg_version} pgmemcache-${pg_version} pgmp${pg_version} pgq-${pg_version} pgrouting_${pg_version} pgtap${pg_version} plpgsql_check_${pg_version} plr${pg_version} plsh${pg_version} postgresql_anonymizer${pg_version} postgresql-unit${pg_version} powa_${pg_version} prefix${pg_version} repmgr${pg_version} safeupdate_${pg_version} semver${pg_version} slony1-${pg_version} sqlite_fdw${pg_version} sslutils_${pg_version} system_stats_${pg_version} table_version${pg_version} topn_${pg_version}

# unified replication user
pg_replication_username: replicator
pg_replication_password: replicator

# unified monitor user
pg_monitor_username: dbuser_monitor
pg_monitor_password: dbuser_monitor


# patroni haproxy vip
# patroni_pause: true                     # use maintenance mode by default
# pg_lb_enabled: true                     # default load balancer type
# pg_lb_vip_enabled: true                 # create vip for load balancer


#------------------------------------------------------------------------------
# MONITOR PROVISION
#------------------------------------------------------------------------------
# - monitor options -
node_exporter_port: 9100                # default port for node exporter
pg_exporter_port: 9630                  # default port for pg exporter
pgbouncer_exporter_port: 9631           # default port for pgbouncer exporter
exporter_metrics_path: /metrics         # default metric path for pg related exporter


...
